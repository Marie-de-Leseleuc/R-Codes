# Source: http://machinelearningmastery.com/how-to-estimate-model-accuracy-in-r-using-the-caret-package/ 


#5 approaches for estimating model performance on unseen data. You will also have access to recipes in R using the caret package for each method, that you can copy and paste into your own project, right now.

#Caret package in R
#Caret package in R, from the caret homepage
#Estimating Model Accuracy

W#e have considered model accuracy before in the configuration of test options in a test harness. You can read more in the post: How To Choose The Right Test Options When Evaluating Machine Learning Algorithms.

#In this post you can going to discover 5 different methods that you can use to estimate model accuracy.

#They are as follows and each will be described in turn:
  
  #Data Split
  #Bootstrap
  #k-fold Cross Validation
  #Repeated k-fold Cross Validation
  #Leave One Out Cross Validation

## Data Split

# load the libraries
library(caret)
library(klaR)

# load the iris dataset
data(iris)

# define an 80%/20% train/test split of the dataset
split=0.80
trainIndex <- createDataPartition(iris$Species, p=split, list=FALSE)
data_train <- iris[ trainIndex,]
data_test <- iris[-trainIndex,]

# train a naive bayes model
model <- NaiveBayes(Species~., data=data_train)

# make predictions
x_test <- data_test[,1:4]
y_test <- data_test[,5]
predictions <- predict(model, x_test)

# summarize results
install.packages('e1071', dependencies=TRUE)
confusionMatrix(predictions$class, y_test)


## Bootstrap 

# define training control
train_control <- trainControl(method="boot", number=100)

# train the model
model <- train(Species~., data=iris, trControl=train_control, method="nb")

# summarize results
print(model)

## K-Fold Cross- Validation

# define training control
train_control <- trainControl(method="cv", number=10)

# fix the parameters of the algorithm
grid <- expand.grid(.fL=c(0), .usekernel=c(FALSE))

# train the model
model <- train(Species~., data=iris, trControl=train_control, method="nb", tuneGrid=grid)

# summarize results
print(model)

##  Repeated K-Fold Cross- Validation

# define training control
train_control <- trainControl(method="repeatedcv", number=10, repeats=3)

# train the model
model <- train(Species~., data=iris, trControl=train_control, method="nb")

# summarize results
print(model)

## Leave One Out Cross Validation

# define training control
train_control <- trainControl(method="LOOCV")

# train the model
model <- train(Species~., data=iris, trControl=train_control, method="nb")

# summarize results
print(model)
